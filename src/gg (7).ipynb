{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data manipulation modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as LA1\n",
    "from scipy import misc\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import scipy.special\n",
    "\n",
    "from skimage import color\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "# plot modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "# csv modules\n",
    "import csv\n",
    "\n",
    "# image manipulation modules\n",
    "from PIL import Image\n",
    "\n",
    "# path modules\n",
    "from pathlib import Path\n",
    "\n",
    "# system modules\n",
    "import os\n",
    "\n",
    "# misc modules\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "\"\"\" GLOBALS \"\"\"\n",
    "image_dir_path = 'Desktop/images/'\n",
    "centroids = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PCA():\n",
    "    \n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "        self.principal_components = np.empty([n_components])\n",
    "        self.m = 0\n",
    "\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \n",
    "    \n",
    "        # Fit the model with X.\n",
    "        \n",
    "        self.m = np.mean(X, axis=0)\n",
    "        \n",
    "        #lst = np.array([(X[i]- self.m) * np.vstack((X[i] - self.m)) for i in range(len(X))])\n",
    "        #cov_matrix = np.sum(np.stack(lst, axis=0), axis=0) / len(X)\n",
    " \n",
    "        cov_matrix = np.cov(X.T)  # 0.35 secs\n",
    "       \n",
    "    \n",
    "        cov_matrix_eig = LA1.eig(cov_matrix)    \n",
    "      \n",
    "\n",
    "        \n",
    "   \n",
    "        self.principal_components = np.array([cov_matrix_eig[1][:, i] for i in (cov_matrix_eig[0].argsort()[-self.n_components:][::-1])])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Apply dimensionality reduction to X.\n",
    "        transformed_dataset = [np.dot(self.principal_components, X[i]) for i in range(len(X))]\n",
    "       \n",
    "        \n",
    "        return transformed_dataset\n",
    "\n",
    "def keywithmaxval(d):\n",
    "    v = list(d.values())\n",
    "    k = list(d.keys())\n",
    "    return k[v.index(max(v))]\n",
    "\n",
    "\n",
    "class kmeans():\n",
    "    \n",
    "    def __init__(self, k, init):\n",
    "        self.k = k\n",
    "        self.init = init\n",
    "        self.centroids = []\n",
    "        \n",
    "    \n",
    "    def kmeans_pp_init(self, X):\n",
    "        start = time.time()\n",
    "        cluster_indices = []\n",
    "        \n",
    "        first_cluster_idx = random.randrange(0, len(X))\n",
    "        \n",
    "        self.centroids.append(X[first_cluster_idx])\n",
    "        cluster_indices.append(first_cluster_idx)\n",
    "        \n",
    "        for i in range(self.k - 1):\n",
    "            distances = {}\n",
    "            \n",
    "            for xi_idx, xi in enumerate(X):\n",
    "                # for each element of X\n",
    "                for j in cluster_indices:\n",
    "                    #np.linalg.norm(xi - X[j])\n",
    "                    #distance.cosine(xi, X[j])\n",
    "                    aux_distances = [np.linalg.norm(xi - X[j]) for j in cluster_indices]\n",
    "                # find the distance to nearest centroid to xi\n",
    "                distances[xi_idx] = min(aux_distances)\n",
    "            \n",
    "            # the new centroid is the one with the greatest distance to its nearest centroid.\n",
    "            new_centroid = keywithmaxval(distances)\n",
    "            self.centroids.append(X[new_centroid])\n",
    "            cluster_indices.append(new_centroid)  \n",
    "    \n",
    "    def vanilla_init(self, X):\n",
    "        self.centroids = [X[random.randrange(0, len(X))] for i in range(self.k)]\n",
    "    \n",
    "    def fit_predict(self, X):\n",
    "        global centroids\n",
    "        \n",
    "        if self.init == \"kmeans++\":\n",
    "            self.kmeans_pp_init(X)\n",
    "        else:\n",
    "            self.vanilla_init(X)\n",
    "        \n",
    "        \n",
    "        \n",
    "        E_old = 0\n",
    "        flag = 0\n",
    "        \n",
    "        while True:\n",
    "            clusters = [[] for i in range(self.k)]\n",
    "            distances = []\n",
    "            labels = []\n",
    "            \n",
    "            for xi in X:\n",
    "                # distance.cosine(xi, j)\n",
    "                # np.linalg.norm(xi - j)\n",
    "                distances_centroids = [np.linalg.norm(xi - j) for j in self.centroids]\n",
    "                distances.append(min(distances_centroids))\n",
    "                clusters[np.argmin(distances_centroids)].append(xi)\n",
    "                labels.append(np.argmin(distances_centroids))\n",
    "            \n",
    "        \n",
    "            E_new = sum(distances)\n",
    "            if flag == 1:\n",
    "                if E_old - E_new <= 0:\n",
    "                    centroids = self.centroids\n",
    "                    break\n",
    "            else:\n",
    "                flag = 1\n",
    "            \n",
    "            E_old = E_new\n",
    "        \n",
    "            \n",
    "            for i in range(len(self.centroids)):\n",
    "                self.centroids[i] =  np.mean(np.array(clusters[i]), axis=0)\n",
    "                            \n",
    "        return labels        \n",
    "\n",
    "\n",
    "def SVD(c):\n",
    "    c_rank = np.linalg.matrix_rank(c) \n",
    "    \n",
    "    cTc = c.T@c\n",
    "    ccT = c@c.T\n",
    "    \n",
    "   \n",
    "\n",
    "    w1, V1 = LA1.eigh(ccT)\n",
    "    w1 = np.round(w1, decimals=5)\n",
    "\n",
    "\n",
    "    w2, V2 = LA1.eigh(cTc)\n",
    "    w2 = np.round(w2, decimals=5)\n",
    "\n",
    "    V = np.array([V2[:, i] for i in (w2.argsort()[::-1])])\n",
    "\n",
    "    w1 = -np.sort(-w1)\n",
    "\n",
    "    dimy = int(c.shape[1])\n",
    "\n",
    "    lst = [[0 for i in range(dimy)] for j in range(c_rank)]\n",
    "\n",
    "\n",
    "    for i in range(len(lst)):\n",
    "        for j in range(len(lst[i])):\n",
    "            if i == j:\n",
    "                lst[i][j] = w1[i] ** (1 / 2)\n",
    "    \n",
    "    rows_to_keep = 0\n",
    "    for idx, el in enumerate(lst):\n",
    "        for jdx, jel in enumerate(el):\n",
    "            if jel > 0:\n",
    "                rows_to_keep += 1\n",
    "    \n",
    "\n",
    "    S = np.array(lst[:rows_to_keep])\n",
    "    \n",
    "    lst = [c@V.T[:, i] / np.linalg.norm(c@V.T[:, i]) for i in range(c_rank)] # Gram-Schmidt\n",
    "\n",
    "    U = np.array(lst).T\n",
    "\n",
    "    \n",
    "    print(np.round(U@S@V, decimals=5))\n",
    "    \n",
    "    return (U, S, V)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def grayscale_and_convert_to_nparray(img_path: str):\n",
    "    \n",
    "    img = Image.open(img_path)\n",
    "    imgGray = img.convert('L')\n",
    "\n",
    "    gray_img = np.asarray(imgGray) / 255\n",
    "    return gray_img.flatten()\n",
    "\n",
    "\n",
    "def load_data(image_dir_path):\n",
    "    \n",
    "    dataset_img_names = np.zeros(shape=(0, 4096))\n",
    "   \n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(image_dir_path):\n",
    "        for directory in dirnames:\n",
    "            for img_name in list(os.listdir(image_dir_path + directory))[:50]:\n",
    "                img_path = \"\".join([image_dir_path, directory, \"/\", img_name])\n",
    "               \n",
    "                vec = grayscale_and_convert_to_nparray(img_path)\n",
    "                dataset_img_names = np.vstack([dataset_img_names, vec])\n",
    "    return dataset_img_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def purity(labels):\n",
    "    summ = 0\n",
    "    for i in range(0, 500, 50):\n",
    "        most_freq = most_common(labels[i:i+50])\n",
    "        print(most_freq)\n",
    "        summ += labels[i:i+50].count(most_freq)\n",
    "    return summ / len(labels)\n",
    "\n",
    "def calculate_tp(lst):\n",
    "    lst2 = [i for i in set(lst) if lst.count(i) > 1]\n",
    "\n",
    "    lst3 = [scipy.special.binom(i, 2) for i in set([lst.count(i) for i in lst if i in lst2])]\n",
    "    \n",
    "    return sum(lst3)\n",
    "\n",
    "def segment_lst(lst):\n",
    "    new_lst = []\n",
    "    for i in range(0, 500, 50):\n",
    "        new_lst.append(lst[i:i+50])\n",
    "    return new_lst\n",
    "\n",
    "def calculate_fn(lst):\n",
    "    most_apprncs = [[0] * 10 for i in range(10)]\n",
    "    lst = segment_lst(lst)\n",
    "\n",
    "    final = []\n",
    "    for i in lst:\n",
    "        aux_lst = []\n",
    "        for k in range(len(lst)):\n",
    "            aux_lst.append(i.count(k + 1))\n",
    "        final.append(aux_lst)\n",
    "\n",
    "    final2 = [[] for i in range(len(final))]\n",
    "    for i in range(len(final2)):\n",
    "        for j in final:\n",
    "            final2[i].append(j[i])\n",
    "\n",
    "    summ = 0\n",
    "    for i in final2:    \n",
    "        summ += max(i) * (sum(i)-max(i))\n",
    "        aux_final2 = i\n",
    "        aux_final2.remove(max(aux_final2))\n",
    "    \n",
    "        for j in range(len(aux_final2)):\n",
    "            for k in range(j + 1, len(aux_final2)):\n",
    "                summ += aux_final2[j] * aux_final2[k]\n",
    "            \n",
    "    return summ\n",
    "    \n",
    "\n",
    "def f1_score(labels):\n",
    "    tp_fp = 0\n",
    "    tp = 0\n",
    "    fn = calculate_fn(labels)\n",
    "    \n",
    "    for i in range(0, 500, 50): \n",
    "        n = len(set(labels[i:i+50]))\n",
    "        tp_fp += scipy.special.binom(n, 2)\n",
    "        tp += calculate_tp(labels[i:i+50])\n",
    "        \n",
    "    precision = tp / tp_fp \n",
    "    recall = tp / tp + fn\n",
    "    \n",
    "    return (2 * (precision * recall)) / (precision + recall)\n",
    "\n",
    "\n",
    "\n",
    "X = load_data(image_dir_path)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "trans_dataset = pca.transform(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kmeans = kmeans(k=5, init=\"kmeans++\")\n",
    "labels = kmeans.fit_predict(trans_dataset)\n",
    "\n",
    "#print(labels)\n",
    "print(\"Purity = \" + str(round(purity(labels) * 100, 2)) + \"%\")\n",
    "f1 = f1_score(labels)\n",
    "if f1 >= 100:\n",
    "    print(\"F1_score = 100%\")\n",
    "else:\n",
    "    print(\"F1_score = \" + str(round(f1, 2)) + \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_clusters(labels):\n",
    "    clusters = [[] for i in range(5)]\n",
    "    for idx, el in enumerate(labels):\n",
    "        clusters[el].append(trans_dataset[idx])\n",
    "\n",
    "\n",
    "    \n",
    "    color_lst = ['black', 'b', 'g', 'r', 'y', 'pink', 'orange', 'purple', 'c', 'olive']\n",
    "\n",
    "    for idx, el in enumerate(clusters):\n",
    "        xpoints = np.vstack(el)[:,0]\n",
    "        ypoints = np.vstack(el)[:,1]\n",
    "            \n",
    "        plt.scatter(xpoints, ypoints, c=color_lst[idx])\n",
    "        \n",
    "    plt.title(\"k = 5\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "plot_clusters(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
